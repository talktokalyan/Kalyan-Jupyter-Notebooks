{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAPEX PROJECT EVENTS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Appended files with [Abandoned, Completed and Outstanding] project status CMIE Capex (2014-22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Create and Store Long Form Data from raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIZIO - LONG FORM - PROJECT EVENTS\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n",
      "Events data not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/cjm_23314cv7n8szb95hx4nc0000gn/T/ipykernel_2244/2351940458.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_long.drop(columns=['Proj_Event_Counter'], axis =1, inplace = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LONG\n",
      "(137808, 14)\n",
      "Index(['Company Name', 'Project Name', 'Cost (Rs.million)', 'Project Status',\n",
      "       'Last Updated On', 'Event', 'Company Code', 'Project No.', 'Type',\n",
      "       'Date', 'sub_stage_id', 'stage_id', 'Append_stage_id',\n",
      "       'Append_sub_stage_id'],\n",
      "      dtype='object')\n",
      "FINITO - LONG FORM\n"
     ]
    }
   ],
   "source": [
    "print(\"INIZIO - LONG FORM - PROJECT EVENTS\")\n",
    "\n",
    "### pick Project events file in each of  [Abandoned, Completed and Outstanding]  folder and append to proc_data folder\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "folder_list = ['Completed', 'Abandoned', 'Outstanding']\n",
    "\n",
    "# List to store data from all XLSX files\n",
    "data = []\n",
    "\n",
    "for stub in folder_list: \n",
    "    # Parent folder path\n",
    "    parent_folder = f'/Users/kalyan/Library/CloudStorage/OneDrive-IIMVIZAG/Python-Exercise-KK/Kalyan-Jupyter-Notebooks/Capex/raw_data/{stub}/'\n",
    "    #print('Level:0 ' + stub + parent_folder)\n",
    "\n",
    "    # Iterate through files in the folder\n",
    "    for filename in os.listdir(parent_folder):\n",
    "        if filename.endswith('_Events_total.xlsx'):\n",
    "            #print(filename)\n",
    "            file_path = os.path.join(parent_folder, filename)\n",
    "\n",
    "            # Read XLSX file into a DataFrame\n",
    "            df = pd.read_excel(file_path)\n",
    "\n",
    "            # Append the DataFrame to the data list\n",
    "            data.append(df)\n",
    "        else :\n",
    "            print(\"Events data not found\")\n",
    "\n",
    "# Concatenate all DataFrames in the data list\n",
    "events_df = pd.concat(data)\n",
    "events_df.drop(['FY','Quarter', 'Quarter '], axis=1, inplace = True)\n",
    "# Remove rows where company code , project number and Event info is missing.\n",
    "events_df.dropna(subset=['Company Code','Project No.','Event','Date'], inplace = True )\n",
    "\n",
    "# Remove rows having event info as \"Company contacted but no response\",\"Company contacted successfully\"\n",
    "excl_list = [\"Company contacted but no response\",\"Company contacted successfully\"]\n",
    "events_df = events_df[~events_df.Event.str.contains('|'.join(excl_list))]\n",
    "events_df = events_df[~(events_df['Event']==\"Event\")]\n",
    "\n",
    "# Convert String to Date\n",
    "events_df['Date2']= pd.to_datetime(events_df['Date'])\n",
    "events_df.drop(columns=['Date'], inplace=True)\n",
    "events_df.rename(columns={'Date2': 'Date'}, inplace=True)\n",
    "\n",
    "#### merge with event concordance table to get project stage IDs and substage IDs\n",
    "concord_folder = f'/Users/kalyan/Library/CloudStorage/OneDrive-IIMVIZAG/Python-Exercise-KK/Kalyan-Jupyter-Notebooks/Capex/raw_data/'\n",
    "df_event_hierarchy = pd.read_excel(os.path.join(concord_folder, 'Concordance-Tables-Capex.xlsx'), sheet_name = 'events-concord') # Events (Substage) Alphanumeric code numeric code and region\n",
    "\n",
    "merged_df = pd.merge(events_df, \n",
    "                     df_event_hierarchy[['Event','sub_stage_id','stage_id']],  # removed stage_id\n",
    "                     on='Event', how='left')\n",
    "\n",
    "#### Prepare Long and Wide format data and store in excel files\n",
    "\n",
    "# Group and create date based ascending order for project events\n",
    "group_cols = ['Company Name', 'Project Name','Company Code', 'Project No.']\n",
    "# Group by 'GroupColumn' and Sort by ascending 'Date'\n",
    "merged_df = merged_df.groupby( group_cols,group_keys=False).apply(lambda group: group.sort_values(by='Date'))\n",
    "\n",
    "### Append All event information into a New column \n",
    "# Create a new column 'Appended_sub_stage_id' with appended 'sub_stage_id' values by 'Name'\n",
    "merged_df['Append_stage_id'] = merged_df.groupby(group_cols)['stage_id'].transform(lambda x: ''.join(x))\n",
    "merged_df['Append_sub_stage_id'] = merged_df.groupby(group_cols)['sub_stage_id'].transform(lambda x: ''.join(x))\n",
    "\n",
    "# Function to reorder characters in a string alphabetically\n",
    "def reorder_alphabetically(text):\n",
    "    return ''.join(sorted(text))\n",
    "\n",
    "# Apply the function to the 'TextColumn' and create a new column 'ReorderedText'\n",
    "merged_df['Append_stage_id'] = merged_df['Append_stage_id'].apply(reorder_alphabetically)\n",
    "\n",
    "\n",
    "### Retain data to Long Format - But remove duplicate event records\n",
    "unique_id_list = ['Company Name', 'Project Name', 'Cost (Rs.million)', \n",
    "                  'Project Status', 'Last Updated On', 'Event', \n",
    "                  'Company Code', 'Project No.', 'Type', 'sub_stage_id', 'stage_id',]\n",
    "\n",
    "# Generate a serial counter within each group\n",
    "merged_df['Proj_Event_Counter'] = merged_df.groupby(unique_id_list).cumcount() + 1\n",
    "\n",
    "df_long = merged_df[merged_df['Proj_Event_Counter']<=1]\n",
    "\n",
    "df_long.drop(columns=['Proj_Event_Counter'], axis =1, inplace = True)\n",
    "\n",
    "# Save the LONG DataFrame into Excel\n",
    "print('LONG')\n",
    "out_folder_path = f'/Users/kalyan/Library/CloudStorage/OneDrive-IIMVIZAG/Python-Exercise-KK/Kalyan-Jupyter-Notebooks/Capex/proc_data/'\n",
    "out_file_name_1 = 'Capex_Events_Total_L.xlsx'\n",
    "out_file_path_1 = os.path.join(out_folder_path, out_file_name_1)\n",
    "df_long.to_excel((out_file_path_1), index=False)\n",
    "print(df_long.shape)\n",
    "print(df_long.columns)\n",
    "\n",
    "\n",
    "print('FINITO - LONG FORM')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Wide Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIZIO - WIDE FORM - PROJECT EVENTS\n",
      "['Company Name', 'Project Name', 'Cost (Rs.million)', 'Project Status', 'Last Updated On', 'Company Code', 'Project No.', 'Type', 'Append_stage_id', 'Append_sub_stage_id']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/cjm_23314cv7n8szb95hx4nc0000gn/T/ipykernel_2244/1363871242.py:12: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  df_wide = df_long.pivot(index = idx_list, columns = col_list, values = val_list).reset_index()\n",
      "/var/folders/4h/cjm_23314cv7n8szb95hx4nc0000gn/T/ipykernel_2244/1363871242.py:12: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  df_wide = df_long.pivot(index = idx_list, columns = col_list, values = val_list).reset_index()\n",
      "/var/folders/4h/cjm_23314cv7n8szb95hx4nc0000gn/T/ipykernel_2244/1363871242.py:12: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  df_wide = df_long.pivot(index = idx_list, columns = col_list, values = val_list).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22255, 278)\n",
      "Index(['Company Name', 'Project Name', 'Cost (Rs.million)', 'Project Status',\n",
      "       'Last Updated On', 'Company Code', 'Project No.', 'Type',\n",
      "       'Append_stage_id', 'Append_sub_stage_id',\n",
      "       ...\n",
      "       'stage_id_H7', 'stage_id_H8', 'stage_id_H9', 'stage_id_I3',\n",
      "       'stage_id_I4', 'stage_id_I7', 'FY', 'Quarter', 'Last_Date',\n",
      "       'Elapsed_time'],\n",
      "      dtype='object', length=278)\n",
      "INTERVALLO - WIDE FORM\n"
     ]
    }
   ],
   "source": [
    "print(\"INIZIO - WIDE FORM - PROJECT EVENTS\")\n",
    "\n",
    "########## Convert data to Wide Format ######\n",
    "\n",
    "master_list = df_long.columns\n",
    "col_list = ['sub_stage_id'] # column whose row values will be appended to column heading \n",
    "val_list = ['Date', 'Event', 'stage_id' ]\n",
    "idx_list = [item for item in master_list if item not in col_list and item not in val_list]\n",
    "print(idx_list)\n",
    "\n",
    "# Pivot the DataFrame to wide format\n",
    "df_wide = df_long.pivot(index = idx_list, columns = col_list, values = val_list).reset_index()\n",
    "\n",
    "# Flatten the multi-level column index\n",
    "df_wide.columns = [f'{col[0]}_{col[1]}' if isinstance(col, tuple) else col for col in df_wide.columns]\n",
    "\n",
    "# Remove trailing underscores from column headings\n",
    "df_wide.columns = df_wide.columns.str.rstrip('_')\n",
    "\n",
    "# Generate FY and Quarter Info to enable matching \n",
    "# Function to generate fiscal year column in 'YY-YY' format\n",
    "def gen_FY(date):\n",
    "    year = date.year\n",
    "    fiscal_year = f'{str(year)[-2:]}-{str(year+1)[-2:]}'\n",
    "    return fiscal_year\n",
    "\n",
    "# Function to generate Indian Fiscal Quarters \n",
    "def gen_FY_Q(date):\n",
    "    fiscal_year = date.year\n",
    "    fiscal_year_last_digit = fiscal_year % 100  # Get the last two digits of the year\n",
    "    if date.month >= 4:\n",
    "        quarter = ((date.month - 4) // 3) + 1\n",
    "    else:\n",
    "        quarter = 4  # Quarter 4 of the previous fiscal year\n",
    "        fiscal_year -= 1\n",
    "#     fiscal_year_quarter = f'FY-{fiscal_year_last_digit:02d}-Q{quarter}'\n",
    "    return quarter\n",
    "\n",
    "\n",
    "# Apply the functions to create new columns\n",
    "df_wide['FY'] = df_wide['Date_A1'].apply(gen_FY)\n",
    "df_wide['Quarter'] = df_wide['Date_A1'].apply(gen_FY_Q)\n",
    "\n",
    "#### Create Elapsed Time Variables\n",
    "# Function to create a new column based on string match\n",
    "def last_date(row):\n",
    "    if 'Abandoned' in row['Type']:\n",
    "        selected_date_columns = ['Date_H19', 'Date_H20', 'Date_H21', 'Date_H22']\n",
    "    elif 'Completed' in row['Type']:\n",
    "        selected_date_columns = ['Date_H9']\n",
    "    elif 'Outstanding' in row['Type']:\n",
    "        selected_date_columns = df_wide.filter(regex='^Date_').columns.tolist()\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    selected_dates = row[selected_date_columns]\n",
    "    \n",
    "    # Filter out missing values before finding the maximum\n",
    "    selected_dates = selected_dates.dropna()\n",
    "    \n",
    "    if selected_dates.empty:\n",
    "        return None\n",
    "    \n",
    "    return selected_dates.max()\n",
    "\n",
    "# Apply the function to create a new column 'Last_Date'\n",
    "df_wide['Last_Date'] = df_wide.apply(last_date, axis=1)\n",
    "df_wide['Elapsed_time'] = df_wide['Last_Date']-df_wide['Date_A1']\n",
    "\n",
    "# Convert the 'Quarter' column in df_wide to int64 to enable merge\n",
    "df_wide['Quarter'] = df_wide['Quarter'].astype(int)\n",
    "\n",
    "print(df_wide.shape)\n",
    "print(df_wide.columns)\n",
    "\n",
    "print(\"INTERVALLO - WIDE FORM\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge with Final_Capex Excel File to get product, state and district location and Industry group information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proj.Loc. & SGDP Shape, columns-B4: \n",
      " (81197, 54)\n",
      "[2018 2017 2020 2014 2022 2015 2021 2016 2019]\n",
      "Proj.Loc.& SGDP Shape, columns: \n",
      " (32409, 54)\n",
      "Index(['Company Name', 'Project Name', 'Cost (Rs.million)', 'Project Status',\n",
      "       'Last Updated On', 'Industry Group', 'Ownership Group', 'Project Type',\n",
      "       'Company Code', 'Project No.', 'FY', 'Quarter', 'Type', 'Location',\n",
      "       'District', 'State', 'Products', 'Capacity', 'Units',\n",
      "       'Reason for Stalling of Projects', 'Sector', 'Owner Affliation',\n",
      "       'Foreign', 'st_ut_code', 'region', 'IndG_L0', 'IndG_L4', 'IndG_L8',\n",
      "       'Gross Fiscal Deficit', 'Revenue Deficit', 'Primary Deficit',\n",
      "       'Own Tax Revenue', 'Own Non-Tax Revenue', ' Interest Payments',\n",
      "       'State-wise Pension', 'State-wise Capital Expenditure',\n",
      "       'Capital Outlay', 'Social Sector Expenditure',\n",
      "       ' Gross State Domestic Product', 'GSVA-Agriculture',\n",
      "       'GSVA-Manufacturing', 'GSVA-Construction', 'GSVA-Industry',\n",
      "       'GSVA-Banking and Insurance ', 'GSVA-Services ',\n",
      "       'Per Capita Net State Domestic Product', 'Net State Domestic Product',\n",
      "       'NSVA-Agriculture', 'NSVA-Manufacturing', 'NSVA-Construction',\n",
      "       'NSVA-Industry', 'NSVA-Banking and Insurance', 'NSVA-Services ',\n",
      "       'Year'],\n",
      "      dtype='object')\n",
      "Merged Data Shape & Columns: \n",
      " (22255, 324)\n",
      "Index(['Company Name', 'Project Name', 'Cost (Rs.million)_x', 'Project Status',\n",
      "       'Last Updated On_x', 'Company Code', 'Project No.', 'Type',\n",
      "       'Append_stage_id', 'Append_sub_stage_id',\n",
      "       ...\n",
      "       'GSVA-Services ', 'Per Capita Net State Domestic Product',\n",
      "       'Net State Domestic Product', 'NSVA-Agriculture', 'NSVA-Manufacturing',\n",
      "       'NSVA-Construction', 'NSVA-Industry', 'NSVA-Banking and Insurance',\n",
      "       'NSVA-Services ', 'Year'],\n",
      "      dtype='object', length=324)\n",
      "WIDE\n",
      "FINITO - WIDE FORM\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Write Merged file to Excel \n",
    "in_folder_path_2 = '/Users/kalyan/Library/CloudStorage/OneDrive-IIMVIZAG/Python-Exercise-KK/Kalyan-Jupyter-Notebooks/Capex/proc_data/'\n",
    "in_file_name_2 = 'Final_Capex.xlsx'\n",
    "df_proj_loc = pd.read_excel(os.path.join(in_folder_path_2, in_file_name_2))\n",
    "# print(df_tmp.dtypes)\n",
    "\n",
    "print('Proj.Loc. & SGDP Shape, columns-B4: \\n', df_proj_loc.shape)\n",
    "\n",
    "### Remove duplicate project records. Retain first Location (District) etc. record.\n",
    "common_columns = ['Company Name', 'Project Name',\n",
    "                  'Project Status','Company Code', 'Project No.', 'Type', 'FY', 'Quarter' ]\n",
    "\n",
    "# Generate a serial counter within each group\n",
    "df_proj_loc['Proj_Counter'] = df_proj_loc.groupby(common_columns).cumcount() + 1\n",
    "\n",
    "df_proj_loc = df_proj_loc[df_proj_loc['Proj_Counter']==1]\n",
    "print(df_proj_loc['Year'].unique())\n",
    "df_proj_loc.drop(columns=['Proj_Counter'], axis =1, inplace = True)\n",
    "\n",
    "print('Proj.Loc.& SGDP Shape, columns: \\n', df_proj_loc.shape)\n",
    "print(df_proj_loc.columns)\n",
    "\n",
    "# # merge_events_proj = pd.merge(df_wide, \n",
    "# #                      df_tmp[['Company Name', 'Project Name', 'Project Status','Company Code', \n",
    "# #                              'Project No.', 'Type', 'FY', 'Quarter', \n",
    "# #                              'Location', 'District', 'st_ut_code', 'region',\n",
    "# #                              'Sector', 'Owner Affliation', 'Ownership Group', 'Foreign', \n",
    "# #                              'Industry Group', 'IndG_L0', 'IndG_L4', 'IndG_L8']],\n",
    "# #                      on=common_columns,\n",
    "# #                      how='left')\n",
    "merge_events_proj = pd.merge(df_wide, \n",
    "                     df_proj_loc,\n",
    "                     on=common_columns,\n",
    "                     how='left')\n",
    "print(\"Merged Data Shape & Columns: \\n\", merge_events_proj.shape)\n",
    "print(merge_events_proj.columns)\n",
    "# Save the WIDE DataFrame into Excel\n",
    "print('WIDE')\n",
    "out_folder_path = f'/Users/kalyan/Library/CloudStorage/OneDrive-IIMVIZAG/Python-Exercise-KK/Kalyan-Jupyter-Notebooks/Capex/proc_data/'\n",
    "out_file_name_2 = 'Capex_Events_Total_W.xlsx'\n",
    "out_file_path_2 = os.path.join(out_folder_path, out_file_name_2)\n",
    "merge_events_proj.to_excel((out_file_path_2), index=False)\n",
    "\n",
    "\n",
    "print(\"FINITO - WIDE FORM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['22-23' '21-22' '18-19' '15-16' '19-20' '20-21' '17-18' '16-17' '23-24'\n",
      " '14-15']\n"
     ]
    }
   ],
   "source": [
    "print(merge_events_proj['FY'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 4 3]\n"
     ]
    }
   ],
   "source": [
    "print(merge_events_proj['Quarter'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
